# NLP

In this project, I explore various models in Natural Language Processing (NLP) to enhance text analysis and understanding. I will delve into GloVe (Global Vectors for Word Representation), which generates vector representations for words based on co-occurrence statistics, effectively capturing semantic meanings. Additionally, I will examine One-Hot Encoding (OHE), a technique that converts categorical data into binary vectors, providing a straightforward method for representing words, although it can lead to high-dimensional challenges.

Furthermore, I will utilize pretrained models from Hugging Face, such as BERT and GPT, which excel in understanding language context and can be fine-tuned for specific tasks. I will also implement a zero-shot classification model, enabling text classification into predefined categories without requiring prior examples. Throughout the training process, I will visualize key performance metrics like accuracy and F1 score to validate the effectiveness of each model.


